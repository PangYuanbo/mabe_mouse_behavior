{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V8 Fine-Grained Behavior Detection - Kaggle Submission\n",
    "\n",
    "**Model Info:**\n",
    "- ✅ V8 Multi-task Model (Action + Agent + Target)\n",
    "- ✅ 28 fine-grained behavior classes\n",
    "- ✅ Validation Action Acc: 86.31%\n",
    "- ✅ Agent/Target Acc: 98%+\n",
    "- ⚡ GPU inference ~1-2 hours\n",
    "\n",
    "**Setup:**\n",
    "1. Upload `best_model.pth` to Kaggle Dataset (name: `mabe-v8-model`)\n",
    "2. Add dataset: `mabe-v8-model` (contains best_model.pth)\n",
    "3. Add dataset: `MABe-mouse-behavior-detection` (competition data)\n",
    "4. Enable GPU (T4 or P100)\n",
    "5. Run all cells\n",
    "6. Notebook output = submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"V8 Multi-task Behavior Detection - Kaggle Submission\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define V8 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class V8BehaviorDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    V8 Multi-task Model\n",
    "    Outputs: Action (28 classes) + Agent (4 mice) + Target (4 mice)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=112,\n",
    "        num_actions=28,\n",
    "        num_mice=4,\n",
    "        conv_channels=[128, 256, 512],\n",
    "        lstm_hidden=256,\n",
    "        lstm_layers=2,\n",
    "        dropout=0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.num_actions = num_actions\n",
    "        self.num_mice = num_mice\n",
    "\n",
    "        # Shared convolutional backbone\n",
    "        conv_layers = []\n",
    "        in_channels = input_dim\n",
    "\n",
    "        for out_channels in conv_channels:\n",
    "            conv_layers.extend([\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.conv_backbone = nn.Sequential(*conv_layers)\n",
    "\n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=conv_channels[-1],\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        lstm_output_dim = lstm_hidden * 2\n",
    "\n",
    "        # Action classification head\n",
    "        self.action_head = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_actions)\n",
    "        )\n",
    "\n",
    "        # Agent identification head\n",
    "        self.agent_head = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(128, num_mice)\n",
    "        )\n",
    "\n",
    "        # Target identification head\n",
    "        self.target_head = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(128, num_mice)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # Conv expects [B, D, T]\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv_backbone(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        # LSTM\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        # Task-specific predictions\n",
    "        action_logits = self.action_head(x)\n",
    "        agent_logits = self.agent_head(x)\n",
    "        target_logits = self.target_head(x)\n",
    "\n",
    "        return action_logits, agent_logits, target_logits\n",
    "\n",
    "print(\"✓ V8BehaviorDetector model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Action Mapping (28 Fine-grained Behaviors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_TO_ID = {\n",
    "    'background': 0,\n",
    "    # Social (1-7)\n",
    "    'sniff': 1, 'sniffgenital': 2, 'sniffface': 3, 'sniffbody': 4,\n",
    "    'reciprocalsniff': 5, 'approach': 6, 'follow': 7,\n",
    "    # Mating (8-11)\n",
    "    'mount': 8, 'intromit': 9, 'attemptmount': 10, 'ejaculate': 11,\n",
    "    # Aggressive (12-18)\n",
    "    'attack': 12, 'chase': 13, 'chaseattack': 14, 'bite': 15,\n",
    "    'dominance': 16, 'defend': 17, 'flinch': 18,\n",
    "    # Other (19-27)\n",
    "    'avoid': 19, 'escape': 20, 'freeze': 21, 'allogroom': 22,\n",
    "    'shepherd': 23, 'disengage': 24, 'run': 25,\n",
    "    'dominancegroom': 26, 'huddle': 27,\n",
    "}\n",
    "\n",
    "ID_TO_ACTION = {v: k for k, v in ACTION_TO_ID.items()}\n",
    "NUM_ACTIONS = 28\n",
    "\n",
    "print(f\"✓ {NUM_ACTIONS} action classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {device}\")\n\nif device.type == 'cuda':\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\nprint()\n\n# Load checkpoint (adjust path to your Kaggle dataset)\nMODEL_PATH = Path('/kaggle/input/mabe-v8-model/last_model.pth')\n\nif not MODEL_PATH.exists():\n    raise FileNotFoundError(\n        f\"Model not found at {MODEL_PATH}.\\n\"\n        \"Please upload last_model.pth to a Kaggle dataset named 'mabe-v8-model'\"\n    )\n\n# Build model\nmodel = V8BehaviorDetector(\n    input_dim=112,  # 7 bodyparts × 4 mice × 2 coords + motion features\n    num_actions=NUM_ACTIONS,\n    num_mice=4,\n    conv_channels=[128, 256, 512],\n    lstm_hidden=256,\n    lstm_layers=2,\n    dropout=0.3\n).to(device)\n\n# Load weights\nstate_dict = torch.load(MODEL_PATH, map_location=device)\nmodel.load_state_dict(state_dict)\nmodel.eval()\n\nprint(f\"✓ Model loaded from {MODEL_PATH.name}\")\nprint(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_motion_features(keypoints, fps=33.3):\n",
    "    \"\"\"Add speed and acceleration features\"\"\"\n",
    "    dt = 1.0 / fps\n",
    "    T, D = keypoints.shape\n",
    "\n",
    "    assert D == 56, f\"Expected 56 coords, got {D}\"\n",
    "\n",
    "    num_keypoints = D // 2\n",
    "    coords = keypoints.reshape(T, num_keypoints, 2)\n",
    "\n",
    "    # Velocity\n",
    "    velocity = np.zeros_like(coords)\n",
    "    if T > 1:\n",
    "        velocity[1:] = (coords[1:] - coords[:-1]) / dt\n",
    "        velocity[0] = velocity[1]\n",
    "\n",
    "    speed = np.sqrt(np.sum(velocity ** 2, axis=2, keepdims=True))\n",
    "\n",
    "    # Acceleration\n",
    "    acceleration_vec = np.zeros_like(velocity)\n",
    "    if T > 1:\n",
    "        acceleration_vec[1:] = (velocity[1:] - velocity[:-1]) / dt\n",
    "        acceleration_vec[0] = acceleration_vec[1]\n",
    "\n",
    "    acceleration = np.sqrt(np.sum(acceleration_vec ** 2, axis=2, keepdims=True))\n",
    "\n",
    "    # Concatenate: [coords, speed, accel]\n",
    "    keypoints_flat = coords.reshape(T, -1)\n",
    "    speed_flat = speed.squeeze(-1)\n",
    "    accel_flat = acceleration.squeeze(-1)\n",
    "\n",
    "    enhanced = np.concatenate([keypoints_flat, speed_flat, accel_flat], axis=1)\n",
    "\n",
    "    return enhanced\n",
    "\n",
    "\n",
    "def predictions_to_intervals(action_preds, agent_preds, target_preds, min_duration=5):\n",
    "    \"\"\"Convert frame-level predictions to interval format\"\"\"\n",
    "    T = len(action_preds)\n",
    "    intervals = []\n",
    "\n",
    "    current_action = None\n",
    "    current_agent = None\n",
    "    current_target = None\n",
    "    start_frame = 0\n",
    "\n",
    "    for t in range(T):\n",
    "        action = action_preds[t]\n",
    "        agent = agent_preds[t]\n",
    "        target = target_preds[t]\n",
    "\n",
    "        # Skip background (action_id = 0)\n",
    "        if action == 0:\n",
    "            if current_action is not None:\n",
    "                duration = t - start_frame\n",
    "                if duration >= min_duration:\n",
    "                    intervals.append({\n",
    "                        'agent_id': current_agent,\n",
    "                        'target_id': current_target,\n",
    "                        'action_id': current_action,\n",
    "                        'action': ID_TO_ACTION.get(current_action, 'background'),\n",
    "                        'start_frame': start_frame,\n",
    "                        'stop_frame': t - 1\n",
    "                    })\n",
    "                current_action = None\n",
    "            continue\n",
    "\n",
    "        # Check if same interval continues\n",
    "        if (action == current_action and agent == current_agent and target == current_target):\n",
    "            continue\n",
    "        else:\n",
    "            # Save previous interval\n",
    "            if current_action is not None:\n",
    "                duration = t - start_frame\n",
    "                if duration >= min_duration:\n",
    "                    intervals.append({\n",
    "                        'agent_id': current_agent,\n",
    "                        'target_id': current_target,\n",
    "                        'action_id': current_action,\n",
    "                        'action': ID_TO_ACTION.get(current_action, 'background'),\n",
    "                        'start_frame': start_frame,\n",
    "                        'stop_frame': t - 1\n",
    "                    })\n",
    "\n",
    "            # Start new interval\n",
    "            current_action = action\n",
    "            current_agent = agent\n",
    "            current_target = target\n",
    "            start_frame = t\n",
    "\n",
    "    # Handle last interval\n",
    "    if current_action is not None:\n",
    "        duration = T - start_frame\n",
    "        if duration >= min_duration:\n",
    "            intervals.append({\n",
    "                'agent_id': current_agent,\n",
    "                'target_id': current_target,\n",
    "                'action_id': current_action,\n",
    "                'action': ID_TO_ACTION.get(current_action, 'background'),\n",
    "                'start_frame': start_frame,\n",
    "                'stop_frame': T - 1\n",
    "            })\n",
    "\n",
    "    return intervals\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find competition dataset\n",
    "possible_paths = [\n",
    "    Path('/kaggle/input/MABe-mouse-behavior-detection'),\n",
    "    Path('/kaggle/input/mabe-mouse-behavior-detection'),\n",
    "]\n",
    "\n",
    "DATA_DIR = None\n",
    "for path in possible_paths:\n",
    "    if path.exists():\n",
    "        DATA_DIR = path\n",
    "        break\n",
    "\n",
    "if DATA_DIR is None:\n",
    "    raise FileNotFoundError(\"Cannot find MABe dataset. Please add it to notebook inputs.\")\n",
    "\n",
    "print(f\"✓ Using dataset: {DATA_DIR}\")\n",
    "\n",
    "# Load test metadata\n",
    "if (DATA_DIR / 'test.csv').exists():\n",
    "    test_csv = pd.read_csv(DATA_DIR / 'test.csv')\n",
    "else:\n",
    "    # Construct from test_tracking directory\n",
    "    test_data = []\n",
    "    for lab_dir in (DATA_DIR / 'test_tracking').iterdir():\n",
    "        if lab_dir.is_dir():\n",
    "            for video_file in lab_dir.glob('*.parquet'):\n",
    "                test_data.append({\n",
    "                    'video_id': video_file.stem,\n",
    "                    'lab_id': lab_dir.name\n",
    "                })\n",
    "    test_csv = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"  Total test videos: {len(test_csv)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard bodyparts\n",
    "standard_bodyparts = [\n",
    "    'nose', 'ear_left', 'ear_right', 'neck',\n",
    "    'hip_left', 'hip_right', 'tail_base'\n",
    "]\n",
    "\n",
    "sequence_length = 100\n",
    "all_intervals = []\n",
    "row_id = 0\n",
    "\n",
    "print(\"Processing test videos...\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, row in tqdm(test_csv.iterrows(), total=len(test_csv)):\n",
    "        video_id = row['video_id']\n",
    "        lab_id = row['lab_id']\n",
    "\n",
    "        tracking_file = DATA_DIR / 'test_tracking' / lab_id / f'{video_id}.parquet'\n",
    "\n",
    "        if not tracking_file.exists():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            tracking_df = pd.read_parquet(tracking_file)\n",
    "            tracking_df = tracking_df[tracking_df['bodypart'].isin(standard_bodyparts)]\n",
    "\n",
    "            if len(tracking_df) == 0 or tracking_df['video_frame'].isna().all():\n",
    "                continue\n",
    "\n",
    "            max_frame = tracking_df['video_frame'].max()\n",
    "            if pd.isna(max_frame):\n",
    "                continue\n",
    "\n",
    "            num_frames = int(max_frame) + 1\n",
    "            num_mice = 4\n",
    "            num_bodyparts = len(standard_bodyparts)\n",
    "\n",
    "            # Pivot\n",
    "            x_pivot = tracking_df.pivot_table(\n",
    "                index='video_frame',\n",
    "                columns=['mouse_id', 'bodypart'],\n",
    "                values='x',\n",
    "                aggfunc='first'\n",
    "            )\n",
    "            y_pivot = tracking_df.pivot_table(\n",
    "                index='video_frame',\n",
    "                columns=['mouse_id', 'bodypart'],\n",
    "                values='y',\n",
    "                aggfunc='first'\n",
    "            )\n",
    "\n",
    "            keypoints_raw = np.zeros((num_frames, num_mice * num_bodyparts * 2), dtype=np.float32)\n",
    "\n",
    "            for mouse_id in range(1, 5):\n",
    "                for bp_idx, bodypart in enumerate(standard_bodyparts):\n",
    "                    if (mouse_id, bodypart) in x_pivot.columns:\n",
    "                        frames = x_pivot.index.values.astype(int)\n",
    "                        x_vals = x_pivot[(mouse_id, bodypart)].values\n",
    "                        y_vals = y_pivot[(mouse_id, bodypart)].values\n",
    "\n",
    "                        base_idx = (mouse_id - 1) * num_bodyparts * 2 + bp_idx * 2\n",
    "                        keypoints_raw[frames, base_idx] = x_vals\n",
    "                        keypoints_raw[frames, base_idx + 1] = y_vals\n",
    "\n",
    "            keypoints = np.nan_to_num(keypoints_raw, nan=0.0)\n",
    "            keypoints = add_motion_features(keypoints, fps=33.3)\n",
    "\n",
    "            # Predict with sliding window (no overlap for inference)\n",
    "            T = len(keypoints)\n",
    "            action_preds = np.zeros(T, dtype=np.int64)\n",
    "            agent_preds = np.zeros(T, dtype=np.int64)\n",
    "            target_preds = np.zeros(T, dtype=np.int64)\n",
    "\n",
    "            for start_idx in range(0, T, sequence_length):\n",
    "                end_idx = min(start_idx + sequence_length, T)\n",
    "                window_len = end_idx - start_idx\n",
    "\n",
    "                if window_len < sequence_length:\n",
    "                    window = np.zeros((sequence_length, 112), dtype=np.float32)\n",
    "                    window[:window_len] = keypoints[start_idx:end_idx]\n",
    "                else:\n",
    "                    window = keypoints[start_idx:end_idx]\n",
    "\n",
    "                window_tensor = torch.FloatTensor(window).unsqueeze(0).to(device)\n",
    "                action_logits, agent_logits, target_logits = model(window_tensor)\n",
    "\n",
    "                action_pred = action_logits[0].argmax(dim=-1).cpu().numpy()\n",
    "                agent_pred = agent_logits[0].argmax(dim=-1).cpu().numpy()\n",
    "                target_pred = target_logits[0].argmax(dim=-1).cpu().numpy()\n",
    "\n",
    "                valid_len = window_len\n",
    "                action_preds[start_idx:end_idx] = action_pred[:valid_len]\n",
    "                agent_preds[start_idx:end_idx] = agent_pred[:valid_len]\n",
    "                target_preds[start_idx:end_idx] = target_pred[:valid_len]\n",
    "\n",
    "            # Convert to intervals\n",
    "            intervals = predictions_to_intervals(\n",
    "                action_preds, agent_preds, target_preds, min_duration=5\n",
    "            )\n",
    "\n",
    "            # Add to submission\n",
    "            for interval in intervals:\n",
    "                all_intervals.append({\n",
    "                    'row_id': row_id,\n",
    "                    'video_id': video_id,\n",
    "                    'agent_id': f\"mouse{interval['agent_id'] + 1}\",\n",
    "                    'target_id': f\"mouse{interval['target_id'] + 1}\",\n",
    "                    'action': interval['action'],\n",
    "                    'start_frame': interval['start_frame'],\n",
    "                    'stop_frame': interval['stop_frame']\n",
    "                })\n",
    "                row_id += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\n✓ Generated {len(all_intervals)} behavior intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "if len(all_intervals) == 0:\n",
    "    print(\"[!] WARNING: No predictions generated!\")\n",
    "    submission = pd.DataFrame(columns=[\n",
    "        'row_id', 'video_id', 'agent_id', 'target_id',\n",
    "        'action', 'start_frame', 'stop_frame'\n",
    "    ])\n",
    "else:\n",
    "    submission = pd.DataFrame(all_intervals)\n",
    "\n",
    "# Save\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "print(f\"✓ Submission saved to /kaggle/working/submission.csv\")\n",
    "print(f\"  Total intervals: {len(submission):,}\")\n",
    "print(f\"  Unique videos: {submission['video_id'].nunique()}\")\n",
    "print(f\"\\n  Action distribution:\")\n",
    "for action, count in submission['action'].value_counts().head(10).items():\n",
    "    print(f\"    {action}: {count}\")\n",
    "\n",
    "print(\"\\n🎯 V8 Submission ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}