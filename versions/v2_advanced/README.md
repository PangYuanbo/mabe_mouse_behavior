# V2 - é«˜çº§æ¨¡å‹ç‰ˆæœ¬

## ğŸ“‹ ç‰ˆæœ¬æ¦‚è¿°

**ç‰ˆæœ¬å·**: V2
**å¼€å‘æ—¶é—´**: V1ä¹‹å
**çŠ¶æ€**: å·²å‡çº§è‡³V3
**ç›®æ ‡**: å¼•å…¥SOTAæ¨¡å‹æ¶æ„ï¼Œæ·»åŠ ç‰¹å¾å·¥ç¨‹

---

## ğŸ¯ è®¾è®¡æ€æƒ³

### æ ¸å¿ƒç›®æ ‡
1. å¼•å…¥ç ”ç©¶è®ºæ–‡ä¸­çš„å…ˆè¿›æ¶æ„ï¼ˆConv1DBiLSTMï¼‰
2. å®ç°ç‰¹å¾å·¥ç¨‹æå‡æ¨¡å‹æ€§èƒ½
3. æ·»åŠ æ­£åˆ™åŒ–å’Œä¼˜åŒ–ç­–ç•¥

### V1 â†’ V2 ä¸»è¦æ”¹è¿›
- âœ… **æ¨¡å‹å‡çº§**: ä»ç®€å•å…¨è¿æ¥ â†’ Conv1D + BiLSTM
- âœ… **ç‰¹å¾å·¥ç¨‹**: æ·»åŠ PCAã€æ—¶åºç»Ÿè®¡ç‰¹å¾
- âœ… **æ•°æ®å¢å¼º**: Mixupã€å™ªå£°æ³¨å…¥ã€æ—¶åºæŠ–åŠ¨
- âœ… **è®­ç»ƒä¼˜åŒ–**: å­¦ä¹ ç‡è°ƒåº¦ã€æ—©åœã€æ¢¯åº¦è£å‰ª
- âœ… **å¤šæ¨¡å‹æ”¯æŒ**: Conv1DBiLSTMã€TCNã€Hybridã€Transformer

### æŠ€æœ¯é€‰æ‹©
- **å¹³å°**: æœ¬åœ°GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
- **æ•°æ®**: ä»ä½¿ç”¨åˆæˆæ•°æ®
- **æ¨¡å‹**: Conv1DBiLSTMï¼ˆç ”ç©¶è¡¨æ˜96%å‡†ç¡®ç‡ï¼‰
- **æ¡†æ¶**: PyTorch + é«˜çº§è®­ç»ƒæŠ€å·§

---

## ğŸ—ï¸ æ¨¡å‹ç»“æ„

### 1. Conv1D + BiLSTM (ä¸»æ¨)

```python
class Conv1DBiLSTMModel(nn.Module):
    """
    Conv1D + BiLSTM æ¶æ„
    - æ¥æºï¼šMABeç«èµ›winning solution
    - æ€§èƒ½ï¼šç ”ç©¶è®ºæ–‡ä¸­è¾¾åˆ°96%å‡†ç¡®ç‡
    """
    def __init__(self, input_dim, conv_channels, lstm_hidden, lstm_layers, num_classes, dropout=0.3):
        super().__init__()

        # Conv1D layers for local feature extraction
        self.conv_layers = nn.ModuleList()
        in_channels = input_dim
        for out_channels in conv_channels:
            self.conv_layers.append(nn.Sequential(
                nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),
                nn.BatchNorm1d(out_channels),
                nn.ReLU(),
                nn.Dropout(dropout)
            ))
            in_channels = out_channels

        # BiLSTM for temporal modeling
        self.lstm = nn.LSTM(
            input_size=conv_channels[-1],
            hidden_size=lstm_hidden,
            num_layers=lstm_layers,
            batch_first=True,
            bidirectional=True,
            dropout=dropout if lstm_layers > 1 else 0
        )

        # Classification head
        self.fc = nn.Linear(lstm_hidden * 2, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        # x: (batch, seq_len, input_dim)
        x = x.transpose(1, 2)  # (batch, input_dim, seq_len)

        # Conv1D layers
        for conv in self.conv_layers:
            x = conv(x)

        x = x.transpose(1, 2)  # (batch, seq_len, conv_channels[-1])

        # BiLSTM
        lstm_out, _ = self.lstm(x)  # (batch, seq_len, lstm_hidden*2)

        # Classification
        out = self.dropout(lstm_out)
        out = self.fc(out)  # (batch, seq_len, num_classes)

        return out
```

### 2. TCN (Temporal Convolutional Network)

```python
class TCNModel(nn.Module):
    """
    Temporal Convolutional Network
    - ä¼˜åŠ¿ï¼šå¹¶è¡Œè®¡ç®—å¿«ï¼Œæ„Ÿå—é‡å¤§
    - é€‚ç”¨ï¼šé•¿åºåˆ—å»ºæ¨¡
    """
    def __init__(self, input_dim, tcn_channels, kernel_size, num_classes, dropout=0.3):
        super().__init__()

        self.tcn_layers = nn.ModuleList()
        in_channels = input_dim

        for i, out_channels in enumerate(tcn_channels):
            dilation = 2 ** i
            self.tcn_layers.append(nn.Sequential(
                nn.Conv1d(in_channels, out_channels, kernel_size,
                         padding=(kernel_size-1)*dilation, dilation=dilation),
                nn.BatchNorm1d(out_channels),
                nn.ReLU(),
                nn.Dropout(dropout)
            ))
            in_channels = out_channels

        self.fc = nn.Linear(tcn_channels[-1], num_classes)
```

### 3. Hybrid (PointNet + LSTM)

```python
class HybridModel(nn.Module):
    """
    Hybridæ¶æ„ï¼šPointNetæå–ç©ºé—´ç‰¹å¾ + LSTMå»ºæ¨¡æ—¶åº
    - PointNet: å¤„ç†æ— åºç‚¹äº‘ï¼ˆé¼ æ ‡å…³é”®ç‚¹ï¼‰
    - LSTM: æ•æ‰æ—¶åºä¾èµ–
    """
    def __init__(self, input_dim, pointnet_dim, temporal_hidden, num_classes, dropout=0.3):
        super().__init__()

        # PointNet for spatial features
        self.pointnet = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, pointnet_dim)
        )

        # LSTM for temporal modeling
        self.lstm = nn.LSTM(pointnet_dim, temporal_hidden,
                           num_layers=2, batch_first=True, bidirectional=True)

        self.fc = nn.Linear(temporal_hidden * 2, num_classes)
```

### æ¨¡å‹å‚æ•°å¯¹æ¯”

| æ¨¡å‹ | å‚æ•°é‡ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|------|--------|------|------|
| Conv1DBiLSTM | ~2M | å‡†ç¡®ç‡é«˜ã€æ—¶åºå»ºæ¨¡å¼º | è®­ç»ƒè¾ƒæ…¢ |
| TCN | ~1.5M | é€Ÿåº¦å¿«ã€å¹¶è¡ŒåŒ–å¥½ | é•¿ä¾èµ–è¾ƒå¼± |
| Hybrid | ~1.8M | ç©ºé—´å»ºæ¨¡å¼º | å¤æ‚åº¦é«˜ |
| Transformer | ~3M | æ³¨æ„åŠ›æœºåˆ¶ | æ•°æ®éœ€æ±‚å¤§ |

---

## âš™ï¸ é…ç½®æ–‡ä»¶

**æ–‡ä»¶**: `configs/config_advanced.yaml`

```yaml
# V2 é«˜çº§é…ç½®
model_type: 'conv_bilstm'  # ä¸»æ¨æ¨¡å‹

# Conv1DBiLSTMå‚æ•°
conv_channels: [64, 128, 256]  # 3å±‚Conv1D
lstm_hidden: 256
lstm_layers: 2

# ç‰¹å¾å·¥ç¨‹
use_feature_engineering: true
include_pca: true
pca_components: 16
include_temporal_stats: true

# åºåˆ—è®¾ç½®
sequence_length: 100  # 3ç§’ @ 33.3Hz
frame_gap: 1
fps: 33.3

# è®­ç»ƒè®¾ç½®
epochs: 100
batch_size: 64
learning_rate: 0.0003
weight_decay: 0.0001
optimizer: 'adamw'
grad_clip: 1.0

# æŸå¤±å‡½æ•°
loss: 'cross_entropy'
class_weights: [0.5, 10.0, 15.0, 15.0]
label_smoothing: 0.0  # é’ˆå¯¹ä¸å¹³è¡¡æ•°æ®ç¦ç”¨

# å­¦ä¹ ç‡è°ƒåº¦
scheduler: 'plateau'
scheduler_patience: 5
scheduler_factor: 0.5
min_lr: 0.00001

# æ•°æ®å¢å¼º
use_augmentation: true
noise_std: 0.01  # é«˜æ–¯å™ªå£°
temporal_jitter: 2  # æ—¶åºæŠ–åŠ¨

# æ­£åˆ™åŒ–
dropout: 0.3
mixup_alpha: 0.0  # ä¸å¹³è¡¡æ•°æ®ç¦ç”¨Mixup

# æ—©åœ
early_stopping_patience: 15
```

---

## ğŸ”§ ç‰¹å¾å·¥ç¨‹

### 1. åŸºç¡€ç‰¹å¾ (28ç»´)
- åŸå§‹åæ ‡ï¼š2åªè€é¼  Ã— 7ä¸ªå…³é”®ç‚¹ Ã— 2åæ ‡ = 28ç»´

### 2. PCAç‰¹å¾ (16ç»´)
```python
from sklearn.decomposition import PCA

pca = PCA(n_components=16)
pca_features = pca.fit_transform(keypoints)
# é™ç»´ï¼šä¿ç•™ä¸»è¦å˜åŒ–æ–¹å‘
```

### 3. æ—¶åºç»Ÿè®¡ç‰¹å¾
- å‡å€¼ã€æ ‡å‡†å·®
- æœ€å¤§å€¼ã€æœ€å°å€¼
- å˜åŒ–ç‡

### æ€»è¾“å…¥ç»´åº¦
28 (åŸå§‹) + 16 (PCA) + å…¶ä»–ç‰¹å¾ = **åŠ¨æ€è°ƒæ•´**

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å®‰è£…ä¾èµ–
```bash
pip install torch torchvision
pip install numpy pandas scikit-learn
pip install pyyaml tqdm
```

### è¿è¡Œè®­ç»ƒ

```bash
# è¿›å…¥V2ç›®å½•
cd versions/v2_advanced/

# ä½¿ç”¨Conv1DBiLSTMè®­ç»ƒï¼ˆé»˜è®¤ï¼‰
python train_advanced.py

# ä½¿ç”¨TCNæ¨¡å‹
python train_advanced.py --model tcn

# ä½¿ç”¨Hybridæ¨¡å‹
python train_advanced.py --model hybrid

# è‡ªå®šä¹‰é…ç½®
python train_advanced.py --config configs/config_advanced.yaml
```

### æ¨¡å‹è¯„ä¼°
```bash
# åŠ è½½æœ€ä½³checkpoint
python evaluate.py --checkpoint checkpoints/best_model.pth
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### è®­ç»ƒç»“æœ
- **Status**: æœ¬åœ°éªŒè¯
- **Dataset**: åˆæˆæ•°æ®ï¼ˆä»æœªä½¿ç”¨çœŸå®Kaggleæ•°æ®ï¼‰
- **Performance**: Conv1DBiLSTMåœ¨åˆæˆæ•°æ®ä¸Šè¡¨ç°è‰¯å¥½

### ç›¸æ¯”V1çš„æå‡
- âœ… **æ¨¡å‹å®¹é‡**: 2å±‚ â†’ æ·±åº¦å·ç§¯+BiLSTM
- âœ… **ç‰¹å¾è¡¨è¾¾**: åŸå§‹åæ ‡ â†’ PCA + æ—¶åºç‰¹å¾
- âœ… **è®­ç»ƒç­–ç•¥**: å›ºå®šLR â†’ è‡ªé€‚åº”è°ƒåº¦ + æ—©åœ
- âœ… **æ­£åˆ™åŒ–**: å•ä¸€Dropout â†’ å¤šç§æ­£åˆ™åŒ–æŠ€æœ¯

### éªŒè¯åŠŸèƒ½
âœ… Conv1Då±‚æ­£ç¡®æå–å±€éƒ¨ç‰¹å¾
âœ… BiLSTMæ•æ‰åŒå‘æ—¶åºä¾èµ–
âœ… å­¦ä¹ ç‡è°ƒåº¦è‡ªåŠ¨é™ä½
âœ… æ—©åœé˜²æ­¢è¿‡æ‹Ÿåˆ
âœ… Checkpointç®¡ç†å®Œå–„

---

## ğŸ” å±€é™æ€§

### ä¸»è¦é—®é¢˜
1. **ä»ä½¿ç”¨åˆæˆæ•°æ®** - æœªåœ¨çœŸå®Kaggleæ•°æ®ä¸Šæµ‹è¯•
2. **ç‰¹å¾å·¥ç¨‹ä¸è¶³** - ç¼ºå°‘é€Ÿåº¦ã€åŠ é€Ÿåº¦ç­‰å…³é”®ç‰¹å¾
3. **æœ¬åœ°è®­ç»ƒ** - ç¼ºä¹GPUèµ„æºï¼Œè®­ç»ƒæ…¢
4. **æ— äº‘ç«¯éƒ¨ç½²** - æœªåˆ©ç”¨Modalç­‰äº‘å¹³å°

### ç¼ºå¤±åŠŸèƒ½
- âŒ çœŸå®Kaggleç«èµ›æ•°æ®
- âŒ Motion featuresï¼ˆé€Ÿåº¦ã€åŠ é€Ÿåº¦ï¼‰
- âŒ äº‘ç«¯GPUè®­ç»ƒ
- âŒ å¤§batchè®­ç»ƒ
- âŒ åˆ†å¸ƒå¼è®­ç»ƒ

---

## ğŸ’¡ ç»éªŒæ•™è®­

### æˆåŠŸç‚¹
1. âœ… Conv1DBiLSTMæ¶æ„éªŒè¯æˆåŠŸ
2. âœ… ç‰¹å¾å·¥ç¨‹æ¡†æ¶æ­å»ºå®Œæˆ
3. âœ… è®­ç»ƒpipelineå®Œå–„ï¼ˆLRè°ƒåº¦ã€æ—©åœç­‰ï¼‰
4. âœ… æ”¯æŒå¤šç§æ¨¡å‹æ¶æ„åˆ‡æ¢

### éœ€æ”¹è¿›
1. âš ï¸ å¿…é¡»åˆ‡æ¢åˆ°çœŸå®Kaggleæ•°æ®
2. âš ï¸ éœ€è¦äº‘ç«¯GPUèµ„æºï¼ˆModalï¼‰
3. âš ï¸ éœ€è¦æ·»åŠ Motion features
4. âš ï¸ éœ€è¦æ›´å¤§çš„batch sizeå’Œæ›´é•¿çš„è®­ç»ƒ

---

## ğŸ“ æ–‡ä»¶ç»“æ„

```
v2_advanced/
â”œâ”€â”€ README.md                   # æœ¬æ–‡æ¡£
â”œâ”€â”€ train_advanced.py           # é«˜çº§è®­ç»ƒè„šæœ¬
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config_advanced.yaml    # é«˜çº§é…ç½®
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ conv_bilstm.py         # Conv1DBiLSTMå®ç°
â”‚   â”œâ”€â”€ tcn.py                 # TCNå®ç°
â”‚   â””â”€â”€ hybrid.py              # Hybridå®ç°
â””â”€â”€ docs/
    â””â”€â”€ (empty)
```

---

## ğŸ”„ å‡çº§åˆ°V3

### ä¸»è¦æ”¹è¿›æ–¹å‘
1. **äº‘ç«¯éƒ¨ç½²** â†’ ä½¿ç”¨Modalå¹³å°
2. **GPUåŠ é€Ÿ** â†’ A10G / T4
3. **çœŸå®æ•°æ®** â†’ å‡†å¤‡Kaggleæ•°æ®é›†æˆ
4. **ä¼˜åŒ–è®­ç»ƒ** â†’ æ›´å¤§batchã€æ›´é•¿è®­ç»ƒ

### è¿ç§»æŒ‡å—
```bash
# æŸ¥çœ‹V3ç‰ˆæœ¬ï¼ˆModalåŸºç¡€ç‰ˆï¼‰
cd ../v3_modal_basic/
cat README.md
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### ç ”ç©¶è®ºæ–‡
- Conv1D + BiLSTM: 96%å‡†ç¡®ç‡
- TCN for sequence modeling
- PointNet for unordered point clouds

### ä»£ç ä½ç½®
- è®­ç»ƒè„šæœ¬: `train_advanced.py`
- æ¨¡å‹å®šä¹‰: `models/`
- é…ç½®æ–‡ä»¶: `configs/config_advanced.yaml`

### ç›¸å…³æ–‡æ¡£
- [V1_README.md](../v1_basic/README.md) - ä¸Šä¸€ç‰ˆæœ¬
- [V3_README.md](../v3_modal_basic/README.md) - ä¸‹ä¸€ç‰ˆæœ¬
- [VERSION_HISTORY.md](../../VERSION_HISTORY.md) - å®Œæ•´ç‰ˆæœ¬å†å²

---

**V2 - å¼•å…¥SOTAæ¶æ„ï¼Œå¥ å®šæ¨¡å‹åŸºç¡€** ğŸš€
