# V3 - Modaläº‘ç«¯åŸºç¡€ç‰ˆæœ¬

## ğŸ“‹ ç‰ˆæœ¬æ¦‚è¿°

**ç‰ˆæœ¬å·**: V3
**å¼€å‘æ—¶é—´**: V2ä¹‹å
**çŠ¶æ€**: å·²å‡çº§è‡³V4
**ç›®æ ‡**: è¿ç§»è‡³Modaläº‘å¹³å°ï¼Œå®ç°GPUåŠ é€Ÿè®­ç»ƒ

---

## ğŸ¯ è®¾è®¡æ€æƒ³

### æ ¸å¿ƒç›®æ ‡
1. ä»æœ¬åœ°è¿ç§»è‡³Modaläº‘å¹³å°
2. åˆ©ç”¨äº‘ç«¯GPUåŠ é€Ÿè®­ç»ƒ
3. éªŒè¯Modaléƒ¨ç½²æµç¨‹

### V2 â†’ V3 ä¸»è¦æ”¹è¿›
- âœ… **äº‘ç«¯éƒ¨ç½²**: æœ¬åœ° â†’ Modaläº‘å¹³å°
- âœ… **GPUèµ„æº**: æœ¬åœ°GPU â†’ Modal T4/A10G
- âœ… **å¯æ‰©å±•æ€§**: å›ºå®šèµ„æº â†’ æŒ‰éœ€åˆ†é…
- âœ… **æŒä¹…åŒ–**: æœ¬åœ°å­˜å‚¨ â†’ Modal Volume

### æŠ€æœ¯é€‰æ‹©
- **å¹³å°**: Modal (workspace: ybpang-1)
- **GPU**: T4 (16GB VRAM)
- **æ•°æ®**: ä»ä½¿ç”¨åˆæˆæ•°æ®
- **æ¨¡å‹**: Transformerï¼ˆæµ‹è¯•äº‘ç«¯æ€§èƒ½ï¼‰
- **å­˜å‚¨**: Modal VolumeæŒä¹…åŒ–

---

## ğŸ—ï¸ Modalæ¶æ„

### Modalå‡½æ•°å®šä¹‰

```python
import modal

app = modal.App("mabe-training-basic")

# å®šä¹‰å®¹å™¨é•œåƒ
image = (modal.Image.debian_slim()
    .pip_install(
        "torch",
        "torchvision",
        "numpy",
        "pandas",
        "pyyaml",
        "tqdm",
        "scikit-learn"
    ))

# å®šä¹‰æŒä¹…åŒ–Volume
volume = modal.Volume.from_name("mabe-data", create_if_missing=True)

@app.function(
    image=image,
    gpu="T4",  # 16GB VRAM
    volumes={"/vol": volume},
    timeout=3600 * 2,  # 2å°æ—¶è¶…æ—¶
)
def train_model():
    """äº‘ç«¯è®­ç»ƒå‡½æ•°"""
    import torch
    from src.trainers.trainer import Trainer
    from src.models.transformer import TransformerModel

    # è®­ç»ƒé€»è¾‘
    trainer = Trainer(config)
    trainer.train()

    # ä¿å­˜checkpointåˆ°Volume
    volume.commit()
```

### éƒ¨ç½²æµç¨‹

```bash
# 1. å®‰è£…Modal
pip install modal

# 2. é…ç½®Token
modal token new

# 3. é€‰æ‹©workspace
# é€‰æ‹©: ybpang-1

# 4. éƒ¨ç½²å¹¶è®­ç»ƒ
modal run modal_train.py

# 5. åå°è¿è¡Œï¼ˆç¬”è®°æœ¬å¯ä»¥å…³é—­ï¼‰
modal run --detach modal_train.py
```

---

## ğŸ—ï¸ æ¨¡å‹ç»“æ„

### Transformeræ¨¡å‹

```python
class TransformerModel(nn.Module):
    """
    Transformer for sequence classification
    - è‡ªæ³¨æ„åŠ›æœºåˆ¶æ•æ‰é•¿ç¨‹ä¾èµ–
    - ä½ç½®ç¼–ç è¡¨ç¤ºæ—¶åºä¿¡æ¯
    """
    def __init__(self, input_dim, hidden_dim, num_layers, num_heads,
                 num_classes, dropout=0.1):
        super().__init__()

        # Input projection
        self.input_proj = nn.Linear(input_dim, hidden_dim)

        # Positional encoding
        self.pos_encoder = PositionalEncoding(hidden_dim, dropout)

        # Transformer encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=hidden_dim,
            nhead=num_heads,
            dim_feedforward=hidden_dim * 4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(
            encoder_layer,
            num_layers=num_layers
        )

        # Classification head
        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        # x: (batch, seq_len, input_dim)
        x = self.input_proj(x)  # (batch, seq_len, hidden_dim)
        x = self.pos_encoder(x)
        x = self.transformer(x)  # (batch, seq_len, hidden_dim)
        x = self.fc(x)  # (batch, seq_len, num_classes)
        return x


class PositionalEncoding(nn.Module):
    """æ·»åŠ ä½ç½®ä¿¡æ¯"""
    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)

        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) *
                            (-math.log(10000.0) / d_model))
        pe = torch.zeros(1, max_len, d_model)
        pe[0, :, 0::2] = torch.sin(position * div_term)
        pe[0, :, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)

    def forward(self, x):
        x = x + self.pe[:, :x.size(1)]
        return self.dropout(x)
```

### æ¨¡å‹å‚æ•°
- Input Dim: 28
- Hidden Dim: 256
- Num Layers: 4
- Num Heads: 8
- Dropout: 0.1

---

## âš™ï¸ é…ç½®æ–‡ä»¶

**æ–‡ä»¶**: `configs/config.yaml`

```yaml
# V3 ModalåŸºç¡€é…ç½®

# æ•°æ®è®¾ç½®
train_data_dir: 'data/train'
val_data_dir: 'data/val'

# æ¨¡å‹è®¾ç½®
model_type: 'transformer'
input_dim: 28
num_classes: 4
hidden_dim: 256
num_layers: 4
num_heads: 8
dropout: 0.1

# åºåˆ—è®¾ç½®
sequence_length: 64
frame_gap: 1

# è®­ç»ƒè®¾ç½®
epochs: 10  # åˆå§‹æµ‹è¯•
batch_size: 16  # T4è¾ƒå°batch
learning_rate: 0.0001
weight_decay: 0.00001
optimizer: 'adamw'
grad_clip: 1.0

# å­¦ä¹ ç‡è°ƒåº¦
scheduler: 'cosine'
min_lr: 0.000001

# Checkpoint
checkpoint_dir: 'checkpoints'
save_freq: 5

# Device
device: 'cuda'
seed: 42
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æœ¬åœ°å¼€å‘
```bash
# 1. å®‰è£…ä¾èµ–
pip install modal torch numpy pandas pyyaml

# 2. é…ç½®Modal
modal token new
# é€‰æ‹©workspace: ybpang-1

# 3. æµ‹è¯•Modalè¿æ¥
modal app list
```

### éƒ¨ç½²è®­ç»ƒ

```bash
# è¿›å…¥V3ç›®å½•
cd versions/v3_modal_basic/

# åŒæ­¥è¿è¡Œï¼ˆæµ‹è¯•ç”¨ï¼‰
modal run modal_train.py

# åå°è¿è¡Œï¼ˆæ¨èï¼‰
modal run --detach modal_train.py

# æŸ¥çœ‹æ—¥å¿—
modal app logs mabe-training-basic

# åœæ­¢ä»»åŠ¡
modal app stop mabe-training-basic
```

### ä¸‹è½½checkpoint

```python
# download_checkpoint.py
@app.function(volumes={"/vol": volume})
def download_checkpoint(filename="best_model.pth"):
    checkpoint_path = Path("/vol/checkpoints") / filename
    with open(checkpoint_path, "rb") as f:
        return f.read()

# æœ¬åœ°æ‰§è¡Œ
modal run download_checkpoint.py
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### Modalæ€§èƒ½
- **GPU**: T4 (16GB VRAM)
- **Batch Size**: 16
- **è®­ç»ƒé€Ÿåº¦**: ~30-40 it/s
- **æ¯epochæ—¶é—´**: ~2-3åˆ†é’Ÿï¼ˆå°æ•°æ®é›†ï¼‰

### ç›¸æ¯”V2çš„æå‡
- âœ… **è®­ç»ƒé€Ÿåº¦**: æœ¬åœ°CPU â†’ T4 GPUï¼ˆ~10xåŠ é€Ÿï¼‰
- âœ… **å¯æ‰©å±•æ€§**: å›ºå®šèµ„æº â†’ æŒ‰éœ€ä¼¸ç¼©
- âœ… **ä¾¿æ·æ€§**: ç¬”è®°æœ¬å¯å…³é—­ï¼Œè®­ç»ƒç»§ç»­
- âœ… **æŒä¹…åŒ–**: Volumeè‡ªåŠ¨ä¿å­˜

### éªŒè¯åŠŸèƒ½
âœ… Modaléƒ¨ç½²æˆåŠŸ
âœ… T4 GPUæ­£å¸¸å·¥ä½œ
âœ… VolumeæŒä¹…åŒ–æ­£å¸¸
âœ… Checkpointä¿å­˜å’Œä¸‹è½½
âœ… --detachåå°è¿è¡Œ

---

## ğŸ” å±€é™æ€§

### ä¸»è¦é—®é¢˜
1. **ä»ä½¿ç”¨åˆæˆæ•°æ®** - æœªé›†æˆKaggleçœŸå®æ•°æ®
2. **GPUè¾ƒå°** - T4ä»…16GBï¼Œbatch sizeå—é™
3. **Transformerè€—èµ„æº** - ä¸å¦‚Conv1DBiLSTMé«˜æ•ˆ
4. **è®­ç»ƒè½®æ•°å°‘** - ä»…10 epochsï¼Œæœªå……åˆ†è®­ç»ƒ

### ç¼ºå¤±åŠŸèƒ½
- âŒ çœŸå®Kaggleç«èµ›æ•°æ®
- âŒ æ›´å¤§GPUï¼ˆA10G/A100ï¼‰
- âŒ Conv1DBiLSTMæ¨¡å‹ï¼ˆV2ä¸­éªŒè¯æ›´å¥½ï¼‰
- âŒ Motion features
- âŒ å®Œæ•´è®­ç»ƒï¼ˆ100+ epochsï¼‰

---

## ğŸ’¡ ç»éªŒæ•™è®­

### æˆåŠŸç‚¹
1. âœ… Modaléƒ¨ç½²æµç¨‹éªŒè¯æˆåŠŸ
2. âœ… GPUåŠ é€Ÿæ•ˆæœæ˜¾è‘—
3. âœ… VolumeæŒä¹…åŒ–å¯é 
4. âœ… --detachå®ç°åå°è®­ç»ƒ

### éœ€æ”¹è¿›
1. âš ï¸ éœ€è¦åˆ‡æ¢å›Conv1DBiLSTMï¼ˆV2ä¸­æ›´å¥½ï¼‰
2. âš ï¸ éœ€è¦å‡çº§GPUè‡³A10Gï¼ˆ24GBï¼‰
3. âš ï¸ å¿…é¡»é›†æˆçœŸå®Kaggleæ•°æ®
4. âš ï¸ å¢åŠ è®­ç»ƒè½®æ•°è‡³100+
5. âš ï¸ æ·»åŠ Motion features

### Modalä½¿ç”¨æŠ€å·§
- ğŸ’¡ ä½¿ç”¨`--detach`è¿›è¡Œé•¿æ—¶é—´è®­ç»ƒ
- ğŸ’¡ å®šæœŸ`volume.commit()`é˜²æ­¢æ•°æ®ä¸¢å¤±
- ğŸ’¡ è®¾ç½®åˆç†çš„`timeout`å‚æ•°
- ğŸ’¡ ä½¿ç”¨`modal app logs`æŸ¥çœ‹è¿è¡Œæ—¥å¿—

---

## ğŸ“ æ–‡ä»¶ç»“æ„

```
v3_modal_basic/
â”œâ”€â”€ README.md              # æœ¬æ–‡æ¡£
â”œâ”€â”€ modal_train.py         # Modalè®­ç»ƒè„šæœ¬
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml        # Modalé…ç½®
â””â”€â”€ docs/
    â””â”€â”€ modal_setup.md     # Modalè®¾ç½®æŒ‡å—
```

---

## ğŸ”„ å‡çº§åˆ°V4

### ä¸»è¦æ”¹è¿›æ–¹å‘
1. **æ¨¡å‹åˆ‡æ¢** â†’ Transformer â†’ Conv1DBiLSTM
2. **GPUå‡çº§** â†’ T4 â†’ A10G (24GB)
3. **çœŸå®æ•°æ®** â†’ å‡†å¤‡Kaggleæ•°æ®é›†æˆ
4. **å®Œæ•´è®­ç»ƒ** â†’ 100 epochs
5. **é«˜çº§é…ç½®** â†’ ä½¿ç”¨V2çš„é«˜çº§é…ç½®

### è¿ç§»æŒ‡å—
```bash
# æŸ¥çœ‹V4ç‰ˆæœ¬ï¼ˆModalé«˜çº§ç‰ˆï¼‰
cd ../v4_modal_advanced/
cat README.md
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### Modalæ–‡æ¡£
- [Modal Quickstart](https://modal.com/docs/guide)
- [Modal GPU Guide](https://modal.com/docs/guide/gpu)
- [Modal Volumes](https://modal.com/docs/guide/volumes)

### ä»£ç ä½ç½®
- Modalè®­ç»ƒ: `modal_train.py`
- é…ç½®æ–‡ä»¶: `configs/config.yaml`
- Workspace: `ybpang-1`

### ç›¸å…³æ–‡æ¡£
- [V2_README.md](../v2_advanced/README.md) - ä¸Šä¸€ç‰ˆæœ¬
- [V4_README.md](../v4_modal_advanced/README.md) - ä¸‹ä¸€ç‰ˆæœ¬
- [VERSION_HISTORY.md](../../VERSION_HISTORY.md) - å®Œæ•´ç‰ˆæœ¬å†å²

---

**V3 - äº‘ç«¯éƒ¨ç½²å®ç°ï¼Œå¼€å¯GPUåŠ é€Ÿ** â˜ï¸
