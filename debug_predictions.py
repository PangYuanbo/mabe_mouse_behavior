"""
è°ƒè¯•è„šæœ¬ - æ£€æŸ¥V8æ¨¡å‹çš„é¢„æµ‹åˆ†å¸ƒ
æ‰¾å‡ºä¸ºä»€ä¹ˆåªé¢„æµ‹attackè€Œä¸æ˜¯28ç§è¡Œä¸º
"""

import torch
import yaml
import pandas as pd
import numpy as np
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent))

from versions.v8_fine_grained.v8_model import V8BehaviorDetector
from versions.v8_fine_grained.action_mapping import NUM_ACTIONS, ID_TO_ACTION
from inference_v8_improved import load_model, add_motion_features


def debug_model_predictions():
    """è°ƒè¯•æ¨¡å‹é¢„æµ‹åˆ†å¸ƒ"""
    
    # åŠ è½½é…ç½®å’Œæ¨¡å‹
    config_path = 'configs/config_v8_5090.yaml'
    checkpoint_path = 'checkpoints/v8_5090/best_model.pth'
    
    with open(config_path) as f:
        config = yaml.safe_load(f)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = load_model(checkpoint_path, config, device)
    
    print(f"æ¨¡å‹åŠ è½½å®Œæˆï¼ŒNUM_ACTIONS = {NUM_ACTIONS}")
    print(f"è¡Œä¸ºæ˜ å°„: {list(ID_TO_ACTION.items())}")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    data_dir = Path(config['data_dir'])
    test_csv = data_dir / 'test.csv'
    metadata = pd.read_csv(test_csv)
    
    print(f"\nå¤„ç†æµ‹è¯•è§†é¢‘...")
    
    for idx, row in metadata.iterrows():
        video_id = row['video_id']
        lab_id = row['lab_id']
        
        tracking_file = data_dir / "test_tracking" / lab_id / f"{video_id}.parquet"
        
        if not tracking_file.exists():
            print(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {tracking_file}")
            continue
            
        # å¤„ç†æ•°æ®
        tracking_df = pd.read_parquet(tracking_file)
        
        standard_bodyparts = [
            'nose', 'ear_left', 'ear_right', 'neck',
            'hip_left', 'hip_right', 'tail_base'
        ]
        
        tracking_df = tracking_df[tracking_df['bodypart'].isin(standard_bodyparts)]
        
        if len(tracking_df) == 0:
            continue
            
        max_frame = tracking_df['video_frame'].max()
        num_frames = int(max_frame) + 1
        num_mice = 4
        num_bodyparts = len(standard_bodyparts)
        
        # æ„å»ºå…³é”®ç‚¹æ•°æ®
        x_pivot = tracking_df.pivot_table(
            index='video_frame',
            columns=['mouse_id', 'bodypart'],
            values='x',
            aggfunc='first'
        )
        y_pivot = tracking_df.pivot_table(
            index='video_frame',
            columns=['mouse_id', 'bodypart'],
            values='y',
            aggfunc='first'
        )
        
        keypoints_raw = np.zeros((num_frames, num_mice * num_bodyparts * 2), dtype=np.float32)
        
        for mouse_id in range(1, 5):
            for bp_idx, bodypart in enumerate(standard_bodyparts):
                if (mouse_id, bodypart) in x_pivot.columns:
                    frames = x_pivot.index.values.astype(int)
                    x_vals = x_pivot[(mouse_id, bodypart)].values
                    y_vals = y_pivot[(mouse_id, bodypart)].values
                    
                    base_idx = (mouse_id - 1) * num_bodyparts * 2 + bp_idx * 2
                    keypoints_raw[frames, base_idx] = x_vals
                    keypoints_raw[frames, base_idx + 1] = y_vals
        
        keypoints = np.nan_to_num(keypoints_raw, nan=0.0)
        keypoints = add_motion_features(keypoints, fps=33.3)
        
        print(f"è§†é¢‘ {video_id}: {num_frames} å¸§, ç‰¹å¾ç»´åº¦: {keypoints.shape[1]}")
        
        # é¢„æµ‹ä¸€ä¸ªçª—å£æ¥æŸ¥çœ‹åˆ†å¸ƒ
        sequence_length = config['sequence_length']
        start_idx = 1000  # ä»ä¸­é—´å¼€å§‹å–æ ·
        end_idx = min(start_idx + sequence_length, num_frames)
        
        if end_idx - start_idx >= 50:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å¸§
            window = keypoints[start_idx:end_idx]
            
            if len(window) < sequence_length:
                padded_window = np.zeros((sequence_length, keypoints.shape[1]), dtype=np.float32)
                padded_window[:len(window)] = window
                window = padded_window
            
            window_tensor = torch.FloatTensor(window).unsqueeze(0).to(device)
            
            with torch.no_grad():
                action_logits, agent_logits, target_logits = model(window_tensor)
            
            # åˆ†æé¢„æµ‹åˆ†å¸ƒ
            action_probs = torch.softmax(action_logits[0], dim=-1).cpu().numpy()  # [T, num_actions]
            agent_probs = torch.softmax(agent_logits[0], dim=-1).cpu().numpy()    # [T, 4]
            target_probs = torch.softmax(target_logits[0], dim=-1).cpu().numpy()  # [T, 4]
            
            print(f"\n=== é¢„æµ‹åˆ†æ (å¸§ {start_idx}-{end_idx}) ===")
            
            # æ£€æŸ¥actioné¢„æµ‹åˆ†å¸ƒ
            print("\nğŸ¯ Actioné¢„æµ‹ç»Ÿè®¡:")
            print(f"Action logits shape: {action_logits.shape}")
            print(f"Action probs shape: {action_probs.shape}")
            
            # ç»Ÿè®¡æ¯ä¸ªè¡Œä¸ºçš„å¹³å‡æ¦‚ç‡
            avg_probs = np.mean(action_probs, axis=0)
            max_probs = np.max(action_probs, axis=0)
            
            print(f"\nå„è¡Œä¸ºå¹³å‡æ¦‚ç‡ (å‰10ä¸ª):")
            for i in range(min(10, len(avg_probs))):
                action_name = ID_TO_ACTION.get(i, f'unknown_{i}')
                print(f"  {i:2d} {action_name:15s}: avg={avg_probs[i]:.4f}, max={max_probs[i]:.4f}")
            
            print(f"\nå„è¡Œä¸ºå¹³å‡æ¦‚ç‡ (åé¢çš„):")
            for i in range(10, len(avg_probs)):
                action_name = ID_TO_ACTION.get(i, f'unknown_{i}')
                if avg_probs[i] > 0.01:  # åªæ˜¾ç¤ºæ¦‚ç‡>1%çš„
                    print(f"  {i:2d} {action_name:15s}: avg={avg_probs[i]:.4f}, max={max_probs[i]:.4f}")
            
            # æ‰¾å‡ºæœ€å¤§æ¦‚ç‡çš„é¢„æµ‹
            predicted_actions = np.argmax(action_probs, axis=1)
            unique_preds, counts = np.unique(predicted_actions, return_counts=True)
            
            print(f"\né¢„æµ‹ç»“æœç»Ÿè®¡:")
            for pred_id, count in zip(unique_preds, counts):
                action_name = ID_TO_ACTION.get(pred_id, f'unknown_{pred_id}')
                percentage = count / len(predicted_actions) * 100
                print(f"  {pred_id:2d} {action_name:15s}: {count:4d} å¸§ ({percentage:5.1f}%)")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰éèƒŒæ™¯é¢„æµ‹
            non_background = predicted_actions[predicted_actions != 0]
            if len(non_background) > 0:
                print(f"\néèƒŒæ™¯é¢„æµ‹: {len(non_background)} å¸§")
                unique_nb, counts_nb = np.unique(non_background, return_counts=True)
                for pred_id, count in zip(unique_nb, counts_nb):
                    action_name = ID_TO_ACTION.get(pred_id, f'unknown_{pred_id}')
                    print(f"  {pred_id:2d} {action_name:15s}: {count:4d} å¸§")
            else:
                print(f"\nâš ï¸  æ²¡æœ‰éèƒŒæ™¯é¢„æµ‹ï¼å…¨éƒ¨æ˜¯èƒŒæ™¯ç±»(id=0)")
            
            # æ£€æŸ¥agentå’Œtargeté¢„æµ‹
            predicted_agents = np.argmax(agent_probs, axis=1)
            predicted_targets = np.argmax(target_probs, axis=1)
            
            print(f"\nAgenté¢„æµ‹åˆ†å¸ƒ: {np.bincount(predicted_agents)}")
            print(f"Targeté¢„æµ‹åˆ†å¸ƒ: {np.bincount(predicted_targets)}")
            
            # æ£€æŸ¥ç½®ä¿¡åº¦åˆ†å¸ƒ
            max_action_probs = np.max(action_probs, axis=1)
            print(f"\nç½®ä¿¡åº¦ç»Ÿè®¡:")
            print(f"  å¹³å‡æœ€å¤§æ¦‚ç‡: {np.mean(max_action_probs):.4f}")
            print(f"  æœ€å¤§æ¦‚ç‡åˆ†å¸ƒ:")
            print(f"    >0.9: {np.sum(max_action_probs > 0.9)} å¸§")
            print(f"    >0.8: {np.sum(max_action_probs > 0.8)} å¸§") 
            print(f"    >0.7: {np.sum(max_action_probs > 0.7)} å¸§")
            print(f"    >0.6: {np.sum(max_action_probs > 0.6)} å¸§")
            print(f"    >0.5: {np.sum(max_action_probs > 0.5)} å¸§")
            
            # æ‰¾å‡ºæœ€æœ‰ä¿¡å¿ƒçš„éèƒŒæ™¯é¢„æµ‹
            non_bg_mask = predicted_actions != 0
            if np.any(non_bg_mask):
                non_bg_confidences = max_action_probs[non_bg_mask]
                non_bg_actions = predicted_actions[non_bg_mask]
                
                # æŒ‰ç½®ä¿¡åº¦æ’åº
                sorted_indices = np.argsort(non_bg_confidences)[::-1]
                print(f"\næœ€æœ‰ä¿¡å¿ƒçš„éèƒŒæ™¯é¢„æµ‹ (å‰5ä¸ª):")
                for i in range(min(5, len(sorted_indices))):
                    idx = sorted_indices[i]
                    frame_idx = np.where(non_bg_mask)[0][idx]
                    action_id = non_bg_actions[idx]
                    confidence = non_bg_confidences[idx]
                    action_name = ID_TO_ACTION.get(action_id, f'unknown_{action_id}')
                    print(f"  å¸§{frame_idx}: {action_name} (id={action_id}) ç½®ä¿¡åº¦={confidence:.4f}")
            
            break  # åªåˆ†æç¬¬ä¸€ä¸ªè§†é¢‘


if __name__ == "__main__":
    debug_model_predictions()