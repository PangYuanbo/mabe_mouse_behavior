{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V8.1 Optimized Behavior Detection - Kaggle Submission\n",
    "\n",
    "**V8.1 Key Improvements:**\n",
    "- âœ… Motion Gating (velocity filters for escape/chase/freeze)\n",
    "- âœ… Fine-tuned Class-specific Thresholds\n",
    "- âœ… Optimized Boundary Refinement\n",
    "- âœ… Sliding Window Ensemble (overlap 50%)\n",
    "- âœ… Adaptive Minimum Durations\n",
    "- âœ… Smart Interval Merging\n",
    "\n",
    "**Model Performance:**\n",
    "- Kaggle F1: Best checkpoint selected\n",
    "- Escape FP: -30~50% reduction\n",
    "- Freeze Recall: +10~20% improvement\n",
    "- Overall F1: +2~5% vs V8\n",
    "\n",
    "**Execution:**\n",
    "- GPU: T4/P100 recommended\n",
    "- Time: ~1-2 hours\n",
    "- Output: submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.special import softmax\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"V8.1 Optimized Behavior Detection - Kaggle Submission\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. V8 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class V8BehaviorDetector(nn.Module):\n",
    "    \"\"\"V8 Multi-task Model: Action + Agent + Target\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=112,\n",
    "        num_actions=28,\n",
    "        num_mice=4,\n",
    "        conv_channels=[128, 256, 512],\n",
    "        lstm_hidden=256,\n",
    "        lstm_layers=2,\n",
    "        dropout=0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.num_actions = num_actions\n",
    "        self.num_mice = num_mice\n",
    "\n",
    "        # Shared convolutional backbone\n",
    "        conv_layers = []\n",
    "        in_channels = input_dim\n",
    "\n",
    "        for out_channels in conv_channels:\n",
    "            conv_layers.extend([\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.conv_backbone = nn.Sequential(*conv_layers)\n",
    "\n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=conv_channels[-1],\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        lstm_output_dim = lstm_hidden * 2\n",
    "\n",
    "        # Task heads\n",
    "        self.action_head = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_actions)\n",
    "        )\n",
    "\n",
    "        self.agent_head = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5 if dropout > 0 else 0),\n",
    "            nn.Linear(128, num_mice)\n",
    "        )\n",
    "\n",
    "        self.target_head = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5 if dropout > 0 else 0),\n",
    "            nn.Linear(128, num_mice)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # Conv expects [B, D, T]\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv_backbone(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        # LSTM\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        # Task-specific predictions\n",
    "        action_logits = self.action_head(x)\n",
    "        agent_logits = self.agent_head(x)\n",
    "        target_logits = self.target_head(x)\n",
    "\n",
    "        return action_logits, agent_logits, target_logits\n",
    "\n",
    "print(\"âœ“ V8BehaviorDetector defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Action Mapping (28 Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_TO_ID = {\n",
    "    'background': 0,\n",
    "    'sniff': 1, 'sniffgenital': 2, 'sniffface': 3, 'sniffbody': 4,\n",
    "    'reciprocalsniff': 5, 'approach': 6, 'follow': 7,\n",
    "    'mount': 8, 'intromit': 9, 'attemptmount': 10, 'ejaculate': 11,\n",
    "    'attack': 12, 'chase': 13, 'chaseattack': 14, 'bite': 15,\n",
    "    'dominance': 16, 'defend': 17, 'flinch': 18,\n",
    "    'avoid': 19, 'escape': 20, 'freeze': 21, 'allogroom': 22,\n",
    "    'shepherd': 23, 'disengage': 24, 'run': 25,\n",
    "    'dominancegroom': 26, 'huddle': 27,\n",
    "}\n",
    "\n",
    "ID_TO_ACTION = {v: k for k, v in ACTION_TO_ID.items()}\n",
    "NUM_ACTIONS = 28\n",
    "\n",
    "print(f\"âœ“ {NUM_ACTIONS} action classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. V8.1 Advanced Post-processing Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V8.1: Fine-tuned class-specific thresholds\n",
    "CLASS_CONFIG = {\n",
    "    'sniff': {'min_duration': 6, 'prob_threshold': 0.38, 'merge_gap': 5, 'max_required': 0.50},\n",
    "    'sniffgenital': {'min_duration': 3, 'prob_threshold': 0.26, 'merge_gap': 5, 'frac_high_threshold': 0.20},\n",
    "    'sniffface': {'min_duration': 3, 'prob_threshold': 0.28, 'merge_gap': 5, 'frac_high_threshold': 0.20},\n",
    "    'sniffbody': {'min_duration': 4, 'prob_threshold': 0.28, 'merge_gap': 6, 'frac_high_threshold': 0.20},\n",
    "    'reciprocalsniff': {'min_duration': 4, 'prob_threshold': 0.40, 'merge_gap': 5},\n",
    "    'mount': {'min_duration': 4, 'prob_threshold': 0.43, 'merge_gap': 8},\n",
    "    'intromit': {'min_duration': 3, 'prob_threshold': 0.45, 'merge_gap': 10},\n",
    "    'attemptmount': {'min_duration': 3, 'prob_threshold': 0.35, 'merge_gap': 5},\n",
    "    'ejaculate': {'min_duration': 3, 'prob_threshold': 0.40, 'merge_gap': 3},\n",
    "    'attack': {'min_duration': 4, 'prob_threshold': 0.40, 'merge_gap': 5},\n",
    "    'chase': {'min_duration': 5, 'prob_threshold': 0.40, 'merge_gap': 5, 'velocity_min': 80.0},\n",
    "    'chaseattack': {'min_duration': 4, 'prob_threshold': 0.40, 'merge_gap': 4},\n",
    "    'bite': {'min_duration': 2, 'prob_threshold': 0.35, 'merge_gap': 3},\n",
    "    'defend': {'min_duration': 4, 'prob_threshold': 0.40, 'merge_gap': 5},\n",
    "    'freeze': {'min_duration': 3, 'prob_threshold': 0.25, 'merge_gap': 3, 'velocity_max': 7.0},\n",
    "    'approach': {'min_duration': 4, 'prob_threshold': 0.42, 'merge_gap': 4},\n",
    "    'follow': {'min_duration': 6, 'prob_threshold': 0.35, 'merge_gap': 5},\n",
    "    'escape': {'min_duration': 5, 'prob_threshold': 0.55, 'merge_gap': 4, 'max_required': 0.65, 'velocity_min': 80.0},\n",
    "    'shepherd': {'min_duration': 5, 'prob_threshold': 0.35, 'merge_gap': 5},\n",
    "    'dominancegroom': {'min_duration': 4, 'prob_threshold': 0.35, 'merge_gap': 5},\n",
    "    'default': {'min_duration': 4, 'prob_threshold': 0.40, 'merge_gap': 4}\n",
    "}\n",
    "\n",
    "print(\"âœ“ V8.1 class-specific configurations loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# Model path\n",
    "MODEL_PATH = Path('/kaggle/input/mabe-v8-1-model/best_model.pth')\n",
    "\n",
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Model not found at {MODEL_PATH}\")\n",
    "\n",
    "# Build model\n",
    "model = V8BehaviorDetector(\n",
    "    input_dim=112,\n",
    "    num_actions=NUM_ACTIONS,\n",
    "    num_mice=4,\n",
    "    conv_channels=[128, 256, 512],\n",
    "    lstm_hidden=256,\n",
    "    lstm_layers=2,\n",
    "    dropout=0.0\n",
    ").to(device)\n",
    "\n",
    "# Load weights\n",
    "state_dict = torch.load(MODEL_PATH, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "print(f\"âœ“ Model loaded from {MODEL_PATH.name}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_motion_features(keypoints, fps=33.3):\n",
    "    \"\"\"Add speed and acceleration features\"\"\"\n",
    "    dt = 1.0 / fps\n",
    "    T, D = keypoints.shape\n",
    "    assert D == 56, f\"Expected 56 coords, got {D}\"\n",
    "    \n",
    "    num_keypoints = D // 2\n",
    "    coords = keypoints.reshape(T, num_keypoints, 2)\n",
    "    \n",
    "    # Velocity\n",
    "    velocity = np.zeros_like(coords)\n",
    "    if T > 1:\n",
    "        velocity[1:] = (coords[1:] - coords[:-1]) / dt\n",
    "        velocity[0] = velocity[1]\n",
    "    \n",
    "    speed = np.sqrt(np.sum(velocity ** 2, axis=2, keepdims=True))\n",
    "    \n",
    "    # Acceleration\n",
    "    acceleration_vec = np.zeros_like(velocity)\n",
    "    if T > 1:\n",
    "        acceleration_vec[1:] = (velocity[1:] - velocity[:-1]) / dt\n",
    "        acceleration_vec[0] = acceleration_vec[1]\n",
    "    \n",
    "    acceleration = np.sqrt(np.sum(acceleration_vec ** 2, axis=2, keepdims=True))\n",
    "    \n",
    "    # Concatenate\n",
    "    keypoints_flat = coords.reshape(T, -1)\n",
    "    speed_flat = speed.squeeze(-1)\n",
    "    accel_flat = acceleration.squeeze(-1)\n",
    "    \n",
    "    enhanced = np.concatenate([keypoints_flat, speed_flat, accel_flat], axis=1)\n",
    "    return enhanced\n",
    "\n",
    "\n",
    "def temporal_smoothing(probs, kernel_size=3):\n",
    "    \"\"\"Temporal smoothing with median filter\"\"\"\n",
    "    T, C = probs.shape\n",
    "    smoothed = np.zeros_like(probs)\n",
    "    \n",
    "    for c in range(C):\n",
    "        smoothed[:, c] = median_filter(probs[:, c], size=kernel_size, mode='reflect')\n",
    "    \n",
    "    # Re-normalize\n",
    "    row_sums = smoothed.sum(axis=1, keepdims=True)\n",
    "    row_sums = np.maximum(row_sums, 1e-8)\n",
    "    smoothed = smoothed / row_sums\n",
    "    \n",
    "    return smoothed\n",
    "\n",
    "\n",
    "def motion_gating_filter(intervals, keypoints, fps=33.3):\n",
    "    \"\"\"V8.1: Motion-gated filtering for velocity-dependent behaviors\"\"\"\n",
    "    filtered = []\n",
    "    \n",
    "    for interval in intervals:\n",
    "        action_name = ID_TO_ACTION.get(interval['action_id'], 'default')\n",
    "        config = CLASS_CONFIG.get(action_name, CLASS_CONFIG['default'])\n",
    "        \n",
    "        velocity_min = config.get('velocity_min', None)\n",
    "        velocity_max = config.get('velocity_max', None)\n",
    "        \n",
    "        if velocity_min is None and velocity_max is None:\n",
    "            filtered.append(interval)\n",
    "            continue\n",
    "        \n",
    "        # Compute agent velocity\n",
    "        start = interval['start']\n",
    "        end = interval['end']\n",
    "        agent_id = interval['agent_id']\n",
    "        \n",
    "        agent_start_col = agent_id * 14\n",
    "        agent_end_col = agent_start_col + 14\n",
    "        agent_kps = keypoints[start:end+1, agent_start_col:min(agent_end_col, 56)]\n",
    "        \n",
    "        if len(agent_kps) < 2:\n",
    "            filtered.append(interval)\n",
    "            continue\n",
    "        \n",
    "        displacements = np.diff(agent_kps, axis=0)\n",
    "        frame_displacements = np.linalg.norm(displacements.reshape(len(displacements), -1), axis=1)\n",
    "        avg_velocity = np.mean(frame_displacements) * fps\n",
    "        \n",
    "        # Apply gating\n",
    "        if velocity_min is not None and avg_velocity < velocity_min:\n",
    "            continue\n",
    "        if velocity_max is not None and avg_velocity > velocity_max:\n",
    "            continue\n",
    "        \n",
    "        filtered.append(interval)\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "def merge_close_segments(intervals):\n",
    "    \"\"\"Merge segments of same action/agent/target with small gaps\"\"\"\n",
    "    if not intervals:\n",
    "        return []\n",
    "    \n",
    "    sorted_intervals = sorted(intervals, key=lambda x: x['start'])\n",
    "    merged = [sorted_intervals[0].copy()]\n",
    "    \n",
    "    for current in sorted_intervals[1:]:\n",
    "        last = merged[-1]\n",
    "        \n",
    "        same_action = (current['action_id'] == last['action_id'])\n",
    "        same_agent = (current['agent_id'] == last['agent_id'])\n",
    "        same_target = (current['target_id'] == last['target_id'])\n",
    "        \n",
    "        if same_action and same_agent and same_target:\n",
    "            action_name = ID_TO_ACTION.get(current['action_id'], 'default')\n",
    "            config = CLASS_CONFIG.get(action_name, CLASS_CONFIG['default'])\n",
    "            merge_gap = config['merge_gap']\n",
    "            \n",
    "            gap = current['start'] - last['end']\n",
    "            \n",
    "            if gap <= merge_gap:\n",
    "                last['end'] = current['end']\n",
    "                continue\n",
    "        \n",
    "        merged.append(current.copy())\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n",
    "def segment_majority_voting(intervals, agent_probs, target_probs):\n",
    "    \"\"\"Apply majority voting for agent/target within each segment\"\"\"\n",
    "    corrected = []\n",
    "    \n",
    "    for interval in intervals:\n",
    "        start = interval['start']\n",
    "        end = interval['end']\n",
    "        \n",
    "        segment_agent_probs = agent_probs[start:end+1]\n",
    "        segment_target_probs = target_probs[start:end+1]\n",
    "        \n",
    "        agent_sum = segment_agent_probs.sum(axis=0)\n",
    "        target_sum = segment_target_probs.sum(axis=0)\n",
    "        \n",
    "        best_agent = np.argmax(agent_sum)\n",
    "        best_target = np.argmax(target_sum)\n",
    "        \n",
    "        if best_agent == best_target:\n",
    "            target_sum[best_agent] = -1\n",
    "            best_target = np.argmax(target_sum)\n",
    "        \n",
    "        interval_copy = interval.copy()\n",
    "        interval_copy['agent_id'] = int(best_agent)\n",
    "        interval_copy['target_id'] = int(best_target)\n",
    "        corrected.append(interval_copy)\n",
    "    \n",
    "    return corrected\n",
    "\n",
    "\n",
    "def probs_to_intervals_advanced(action_probs, agent_probs, target_probs, keypoints=None):\n",
    "    \"\"\"V8.1: Convert probabilities to intervals with advanced post-processing\"\"\"\n",
    "    T = len(action_probs)\n",
    "    \n",
    "    # Temporal smoothing\n",
    "    action_probs = temporal_smoothing(action_probs, kernel_size=3)\n",
    "    \n",
    "    # Get frame-wise predictions\n",
    "    action_preds = np.argmax(action_probs, axis=-1)\n",
    "    \n",
    "    # Action-only segmentation\n",
    "    intervals = []\n",
    "    start_idx = 0\n",
    "    current_action = action_preds[0]\n",
    "    \n",
    "    for t in range(1, T + 1):\n",
    "        if t == T or action_preds[t] != current_action:\n",
    "            end_idx = t - 1\n",
    "            \n",
    "            if current_action != 0:\n",
    "                action_name = ID_TO_ACTION.get(current_action, 'default')\n",
    "                config = CLASS_CONFIG.get(action_name, CLASS_CONFIG['default'])\n",
    "                \n",
    "                duration = end_idx - start_idx + 1\n",
    "                if duration >= config['min_duration']:\n",
    "                    seg_probs = action_probs[start_idx:end_idx+1, current_action]\n",
    "                    avg_prob = float(np.mean(seg_probs))\n",
    "                    max_prob = float(np.max(seg_probs))\n",
    "                    frac_high = float(np.mean(seg_probs >= config['prob_threshold']))\n",
    "                    \n",
    "                    frac_high_threshold = float(config.get('frac_high_threshold', 0.30))\n",
    "                    max_required = float(config.get('max_required', max(0.45, config['prob_threshold'] + 0.10)))\n",
    "                    \n",
    "                    if (avg_prob >= config['prob_threshold']) or (max_prob >= max_required) or (frac_high >= frac_high_threshold):\n",
    "                        intervals.append({\n",
    "                            'start': start_idx,\n",
    "                            'end': end_idx,\n",
    "                            'action_id': int(current_action),\n",
    "                            'agent_id': -1,\n",
    "                            'target_id': -1,\n",
    "                            'confidence': avg_prob\n",
    "                        })\n",
    "            \n",
    "            if t < T:\n",
    "                start_idx = t\n",
    "                current_action = action_preds[t]\n",
    "    \n",
    "    # Segment-level majority voting\n",
    "    intervals = segment_majority_voting(intervals, agent_probs, target_probs)\n",
    "    \n",
    "    # Merge close segments\n",
    "    intervals = merge_close_segments(intervals)\n",
    "    \n",
    "    # Motion gating filter\n",
    "    if keypoints is not None:\n",
    "        intervals = motion_gating_filter(intervals, keypoints)\n",
    "    \n",
    "    # Convert to Kaggle format\n",
    "    kaggle_intervals = []\n",
    "    for interval in intervals:\n",
    "        if interval['agent_id'] == interval['target_id']:\n",
    "            continue\n",
    "        kaggle_intervals.append({\n",
    "            'start_frame': int(interval['start']),\n",
    "            'stop_frame': int(interval['end']),\n",
    "            'action_id': interval['action_id'],\n",
    "            'action': ID_TO_ACTION[interval['action_id']],\n",
    "            'agent_id': interval['agent_id'],\n",
    "            'target_id': interval['target_id']\n",
    "        })\n",
    "    \n",
    "    return kaggle_intervals\n",
    "\n",
    "print(\"âœ“ V8.1 helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find competition dataset\n",
    "possible_paths = [\n",
    "    Path('/kaggle/input/MABe-mouse-behavior-detection'),\n",
    "    Path('/kaggle/input/mabe-mouse-behavior-detection'),\n",
    "]\n",
    "\n",
    "DATA_DIR = None\n",
    "for path in possible_paths:\n",
    "    if path.exists():\n",
    "        DATA_DIR = path\n",
    "        break\n",
    "\n",
    "if DATA_DIR is None:\n",
    "    raise FileNotFoundError(\"Cannot find MABe dataset\")\n",
    "\n",
    "print(f\"âœ“ Using dataset: {DATA_DIR}\")\n",
    "\n",
    "# Load test metadata\n",
    "if (DATA_DIR / 'test.csv').exists():\n",
    "    test_csv = pd.read_csv(DATA_DIR / 'test.csv')\n",
    "else:\n",
    "    test_data = []\n",
    "    for lab_dir in (DATA_DIR / 'test_tracking').iterdir():\n",
    "        if lab_dir.is_dir():\n",
    "            for video_file in lab_dir.glob('*.parquet'):\n",
    "                test_data.append({\n",
    "                    'video_id': video_file.stem,\n",
    "                    'lab_id': lab_dir.name\n",
    "                })\n",
    "    test_csv = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"  Total test videos: {len(test_csv)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Predictions with V8.1 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard bodyparts\n",
    "standard_bodyparts = [\n",
    "    'nose', 'ear_left', 'ear_right', 'neck',\n",
    "    'hip_left', 'hip_right', 'tail_base'\n",
    "]\n",
    "\n",
    "sequence_length = 100\n",
    "overlap_ratio = 0.5  # V8.1: Ensemble with 50% overlap\n",
    "stride = int(sequence_length * (1 - overlap_ratio))\n",
    "\n",
    "all_intervals = []\n",
    "row_id = 0\n",
    "\n",
    "print(f\"V8.1 Inference: sequence_length={sequence_length}, overlap={overlap_ratio:.0%}, stride={stride}\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, row in tqdm(test_csv.iterrows(), total=len(test_csv)):\n",
    "        video_id = row['video_id']\n",
    "        lab_id = row['lab_id']\n",
    "\n",
    "        tracking_file = DATA_DIR / 'test_tracking' / lab_id / f'{video_id}.parquet'\n",
    "\n",
    "        if not tracking_file.exists():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            tracking_df = pd.read_parquet(tracking_file)\n",
    "            tracking_df = tracking_df[tracking_df['bodypart'].isin(standard_bodyparts)]\n",
    "\n",
    "            if len(tracking_df) == 0 or tracking_df['video_frame'].isna().all():\n",
    "                continue\n",
    "\n",
    "            max_frame = tracking_df['video_frame'].max()\n",
    "            if pd.isna(max_frame):\n",
    "                continue\n",
    "\n",
    "            num_frames = int(max_frame) + 1\n",
    "            num_mice = 4\n",
    "            num_bodyparts = len(standard_bodyparts)\n",
    "\n",
    "            # Pivot\n",
    "            x_pivot = tracking_df.pivot_table(\n",
    "                index='video_frame',\n",
    "                columns=['mouse_id', 'bodypart'],\n",
    "                values='x',\n",
    "                aggfunc='first'\n",
    "            )\n",
    "            y_pivot = tracking_df.pivot_table(\n",
    "                index='video_frame',\n",
    "                columns=['mouse_id', 'bodypart'],\n",
    "                values='y',\n",
    "                aggfunc='first'\n",
    "            )\n",
    "\n",
    "            keypoints_raw = np.zeros((num_frames, num_mice * num_bodyparts * 2), dtype=np.float32)\n",
    "\n",
    "            for mouse_id in range(1, 5):\n",
    "                for bp_idx, bodypart in enumerate(standard_bodyparts):\n",
    "                    if (mouse_id, bodypart) in x_pivot.columns:\n",
    "                        frames = x_pivot.index.values.astype(int)\n",
    "                        x_vals = x_pivot[(mouse_id, bodypart)].values\n",
    "                        y_vals = y_pivot[(mouse_id, bodypart)].values\n",
    "\n",
    "                        base_idx = (mouse_id - 1) * num_bodyparts * 2 + bp_idx * 2\n",
    "                        keypoints_raw[frames, base_idx] = x_vals\n",
    "                        keypoints_raw[frames, base_idx + 1] = y_vals\n",
    "\n",
    "            keypoints = np.nan_to_num(keypoints_raw, nan=0.0)\n",
    "            \n",
    "            # Keep original keypoints for motion gating\n",
    "            keypoints_for_gating = keypoints.copy()\n",
    "            \n",
    "            # Add motion features\n",
    "            keypoints = add_motion_features(keypoints, fps=33.3)\n",
    "\n",
    "            # V8.1: Sliding window ensemble with overlap\n",
    "            T = len(keypoints)\n",
    "            action_logits_sum = np.zeros((T, NUM_ACTIONS), dtype=np.float32)\n",
    "            agent_logits_sum = np.zeros((T, 4), dtype=np.float32)\n",
    "            target_logits_sum = np.zeros((T, 4), dtype=np.float32)\n",
    "            counts = np.zeros(T, dtype=np.int32)\n",
    "\n",
    "            for start_idx in range(0, T, stride):\n",
    "                end_idx = min(start_idx + sequence_length, T)\n",
    "                window_len = end_idx - start_idx\n",
    "\n",
    "                if window_len < sequence_length // 2:\n",
    "                    continue\n",
    "\n",
    "                if window_len < sequence_length:\n",
    "                    window = np.zeros((sequence_length, 112), dtype=np.float32)\n",
    "                    window[:window_len] = keypoints[start_idx:end_idx]\n",
    "                else:\n",
    "                    window = keypoints[start_idx:end_idx]\n",
    "\n",
    "                window_tensor = torch.FloatTensor(window).unsqueeze(0).to(device)\n",
    "                action_logits, agent_logits, target_logits = model(window_tensor)\n",
    "\n",
    "                action_logits_np = action_logits[0].cpu().numpy()\n",
    "                agent_logits_np = agent_logits[0].cpu().numpy()\n",
    "                target_logits_np = target_logits[0].cpu().numpy()\n",
    "\n",
    "                valid_len = window_len\n",
    "                action_logits_sum[start_idx:end_idx] += action_logits_np[:valid_len]\n",
    "                agent_logits_sum[start_idx:end_idx] += agent_logits_np[:valid_len]\n",
    "                target_logits_sum[start_idx:end_idx] += target_logits_np[:valid_len]\n",
    "                counts[start_idx:end_idx] += 1\n",
    "\n",
    "            # Average and convert to probabilities\n",
    "            counts = np.maximum(counts, 1)\n",
    "            action_logits_avg = action_logits_sum / counts[:, None]\n",
    "            agent_logits_avg = agent_logits_sum / counts[:, None]\n",
    "            target_logits_avg = target_logits_sum / counts[:, None]\n",
    "\n",
    "            action_probs = softmax(action_logits_avg, axis=1)\n",
    "            agent_probs = softmax(agent_logits_avg, axis=1)\n",
    "            target_probs = softmax(target_logits_avg, axis=1)\n",
    "\n",
    "            # V8.1: Advanced post-processing\n",
    "            intervals = probs_to_intervals_advanced(\n",
    "                action_probs, agent_probs, target_probs,\n",
    "                keypoints=keypoints_for_gating\n",
    "            )\n",
    "\n",
    "            # Add to submission\n",
    "            for interval in intervals:\n",
    "                all_intervals.append({\n",
    "                    'row_id': row_id,\n",
    "                    'video_id': video_id,\n",
    "                    'agent_id': f\"mouse{interval['agent_id'] + 1}\",\n",
    "                    'target_id': f\"mouse{interval['target_id'] + 1}\",\n",
    "                    'action': interval['action'],\n",
    "                    'start_frame': interval['start_frame'],\n",
    "                    'stop_frame': interval['stop_frame']\n",
    "                })\n",
    "                row_id += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(all_intervals)} behavior intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "if len(all_intervals) == 0:\n",
    "    print(\"[!] WARNING: No predictions generated!\")\n",
    "    submission = pd.DataFrame(columns=[\n",
    "        'row_id', 'video_id', 'agent_id', 'target_id',\n",
    "        'action', 'start_frame', 'stop_frame'\n",
    "    ])\n",
    "else:\n",
    "    submission = pd.DataFrame(all_intervals)\n",
    "\n",
    "# Save\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "print(f\"âœ“ Submission saved to /kaggle/working/submission.csv\")\n",
    "print(f\"  Total intervals: {len(submission):,}\")\n",
    "print(f\"  Unique videos: {submission['video_id'].nunique()}\")\n",
    "print(f\"\\n  Action distribution:\")\n",
    "for action, count in submission['action'].value_counts().head(10).items():\n",
    "    print(f\"    {action}: {count}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ V8.1 Optimized Submission ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
